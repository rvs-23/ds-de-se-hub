{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "metric-first",
   "metadata": {},
   "source": [
    "# Where to start learning?\n",
    "\n",
    "<a href = \"https://numpy.org/learn/\"> Numpy - Getting Started (Official) </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-transsexual",
   "metadata": {},
   "source": [
    "## What is Numpy? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-blanket",
   "metadata": {},
   "source": [
    "<b>Numerical Python</b>(NumPy) is the fundamental package for scientific computing in Python. It is a Python library that provides a <b>multidimensional array object</b>, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\n",
    "\n",
    "At the core of the NumPy package, is the <u>ndarray object</u>. This encapsulates n-dimensional arrays of <u>homogeneous data types</u>, with many <u>operations being performed in compiled code for performance.</u> There are several important differences between NumPy arrays and the standard Python sequences:\n",
    "<pre>\n",
    "i) NumPy arrays have a fixed size at creation, unlike Python lists (which can grow dynamically). Changing the size of an ndarray will create a new array and delete the original.\n",
    "\n",
    "ii) The elements in a NumPy array are all required to be of the same data type, and thus will be the same size in memory. The exception: one can have arrays of (Python, including NumPy) objects, thereby allowing for arrays of different sized elements.\n",
    "\n",
    "iii) NumPy arrays facilitate advanced mathematical and other types of operations on large numbers of data. Typically, such operations are executed more efficiently and with less code than is possible using Python’s built-in sequences.\n",
    "</pre>\n",
    "\n",
    "A growing plethora of scientific and mathematical Python-based packages are using NumPy arrays; though these typically support Python-sequence input, they convert such input to NumPy arrays prior to processing, and they often output NumPy arrays. Arrays are also frequently used in Data Science where speed and optimal utiization of resources is very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "insured-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spectacular-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "present-rebate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-charter",
   "metadata": {},
   "source": [
    "## Why is Numpy faster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-invitation",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Numpy uses the technique of <b><u>Vectorization</u></b> which describes the absence of any explicit looping, indexing, etc., in the code - these things are taking place, of course, just “behind the scenes” in optimized, pre-compiled C code.</li>\n",
    "<li>Numpy arrays are stored in contiguous memory locations whereas lists are not. Contiguous refers to sections of memory that are next to one another.\n",
    "</li>\n",
    "<li>Numpy package breaks down a task into multiple fragments and process all fragments parallely. Also, it is optimized to work with latest CPU architectures.\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<b>Note</b>: ***Numpy arrays show a reasonable reduction in speeds only when the number of observations involved are very large.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-probability",
   "metadata": {},
   "source": [
    "### <u>Problem statement</u> - Convert a random list of temperatures in Celcius to Fahrenheit. Compare the performances of various method and show how numpy arrays work better with larger data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "awful-blond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 34, 32, 33, 16, 15, 28, 27, 48, 33]\n"
     ]
    }
   ],
   "source": [
    "ten_temp_celcius = [np.random.randint(5, 50) for _ in range(10)]\n",
    "print(ten_temp_celcius)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-character",
   "metadata": {},
   "source": [
    "<b>Let's convert this list of temperatures into Farenheit using three different methods:\n",
    "<pre>\n",
    "i) using loops\n",
    "ii) using list comprehensions\n",
    "iii) using vectorized code</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-longer",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-classroom",
   "metadata": {},
   "source": [
    "#### Method - 1 Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afraid-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.8, 93.2, 89.6, 91.4, 60.8, 59.0, 82.4, 80.6, 118.4, 91.4]\n"
     ]
    }
   ],
   "source": [
    "temp_in_far_l = []\n",
    "\n",
    "for temp in ten_temp_celcius:\n",
    "    temp_in_far_l.append(9/5*temp + 32)\n",
    "\n",
    "print(temp_in_far_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-company",
   "metadata": {},
   "source": [
    "#### Method - 2 : List Comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thirty-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.8, 93.2, 89.6, 91.4, 60.8, 59.0, 82.4, 80.6, 118.4, 91.4]\n"
     ]
    }
   ],
   "source": [
    "temp_in_far_lc = [(c*9/5 + 32) for c in ten_temp_celcius]\n",
    "print(temp_in_far_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-interpretation",
   "metadata": {},
   "source": [
    "#### Method 3 - Vectorized Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "waiting-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 60.8  93.2  89.6  91.4  60.8  59.   82.4  80.6 118.4  91.4]\n"
     ]
    }
   ],
   "source": [
    "temp_in_far_v = (np.array(ten_temp_celcius)*9/5 + 32)\n",
    "print(temp_in_far_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-disposal",
   "metadata": {},
   "source": [
    "### Comparing Performances - 1 (with 10 data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hindu-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "careful-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance of loops\n",
    "\n",
    "method_loops = \"\"\"\n",
    "temp_in_far_l = []\n",
    "\n",
    "for temp in ten_temp_celcius:\n",
    "    temp_in_far_l.append(9/5*temp + 32)\n",
    "\"\"\"\n",
    "\n",
    "method_listc = \"\"\"\n",
    "temp_in_far_lc = [(c*9/5 + 32) for c in ten_temp_celcius]\n",
    "\"\"\"\n",
    "\n",
    "method_vc = \"\"\"\n",
    "temp_in_far_v = (np.array(ten_temp_celcius)*9/5 + 32)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tight-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4717087999999996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method - 1\n",
    "\n",
    "timeit.timeit(method_loops, setup='import random; ten_temp_celcius = [random.randint(5, 50) for _ in range(10)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "related-transaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.653466400000001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method - 2\n",
    "\n",
    "timeit.timeit(method_listc, setup='import random; ten_temp_celcius = [random.randint(5, 50) for _ in range(10)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "banned-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5340723999999994"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method  - 3\n",
    "\n",
    "timeit.timeit(method_vc, setup = \"import numpy as np; ten_temp_celcius = [np.random.randint(5, 50) for _ in range(10)]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-treat",
   "metadata": {},
   "source": [
    "***We can see from the above example that when we considered only 10 data points, the vectorized code took the longest to run. Let's increase the size of the array and repeat the whole thing again.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-richmond",
   "metadata": {},
   "source": [
    "### Comparing Performances - 2 (with 100000 data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "laden-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance of loops\n",
    "\n",
    "method_loops_100000 = \"\"\"\n",
    "temp_in_far_l = []\n",
    "\n",
    "for temp in ht_temp_celcius:\n",
    "    temp_in_far_l.append(9/5*temp + 32)\n",
    "\"\"\"\n",
    "\n",
    "method_listc_100000 = \"\"\"\n",
    "temp_in_far_lc = [(c*9/5 + 32) for c in ht_temp_celcius]\n",
    "\"\"\"\n",
    "\n",
    "method_vc_100000 = \"\"\"\n",
    "temp_in_far_v = (np.array(ht_temp_celcius)*9/5 + 32)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "planned-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.732050199999996"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(method_loops_100000, number=1000, setup='import random; ht_temp_celcius = [random.randint(0, 100) for _ in range(100000)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "selective-sympathy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.370302699999996"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(method_listc_100000, number=1000, setup='import random; ht_temp_celcius = [random.randint(0, 100) for _ in range(100000)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stretch-poison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6267635000000027"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(method_vc_100000, number=1000, setup='import numpy as np; ht_temp_celcius = np.array([np.random.randint(0, 100) for _ in range(100000)])')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-harvest",
   "metadata": {},
   "source": [
    "***As we can see from the above comparison that that this time the vectorized solution is the fastest among all. This is because of the number of data points we had (100000) compared to 10 in the last comparison.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-setting",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vectorization vs Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-holiday",
   "metadata": {},
   "source": [
    "### Vectorization:\n",
    "<p>\n",
    "LOOPS ARE SLOW. Python lists can have any data type. What if we can restrict our lists to have only one data type that we can let Python know in advance? Numpy does something similar. It allows arrays to only have a single data type and stores the data internally in a contiguous block of memory.</p>\n",
    "\n",
    "<p>\n",
    "    <u>VECTORIZATION</u> is a powerful ability withing NumPy to express operations as occuring on <u> entire arrays </u> rather than individual elements.\n",
    "</p>\n",
    "\n",
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h3> Here’s a concise definition from Wes McKinney: </h3>\n",
    "\n",
    "<b> \n",
    "\n",
    "This practice of replacing explicit loops with array expressions is commonly referred to as vectorization. In general, vectorized array operations will often be one or two (or more) orders of magnitude faster than their pure Python equivalents, with the biggest impact [seen] in any kind of numerical computations. </b>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "congressional-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-25,  -5, -20, -45, -25, -30])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([5,1,4,9,5,6]) * -5                        # vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-shopping",
   "metadata": {},
   "source": [
    "### Broadcasting:\n",
    "\n",
    "<p>\n",
    "    Another feature of Numpy Abstraction. The operations between equally sized numpy arrays work great. Like:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "scheduled-controversy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.875     , 4.16666667, 0.38461538, 2.92307692])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([7,25,35,152])\n",
    "b = np.array([8,6,91,52])\n",
    "\n",
    "a/b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-sleeve",
   "metadata": {},
   "source": [
    "***But what if the arrays are unequally sized? This is where broadcasting comes in!***\n",
    "\n",
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h3> Here’s a concise definition from the documentation: </h3>\n",
    "\n",
    "<b> \n",
    "\n",
    "The term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. </b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-heating",
   "metadata": {},
   "source": [
    "<p>\n",
    "The way in which broadcasting is implemented can become tedious when working with more than two arrays. However, if there are just two arrays, then their ability to be broadcasted can be described with two short rules:\n",
    "\n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing dimensions and works its way forward. Two dimensions are compatible when:\n",
    "<pre>\n",
    "<b>1. they are equal, or\n",
    "2. one of them is 1</b>\n",
    "</pre>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "expired-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 4., 6.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1.0, 2.0, 3.0])\n",
    "y = np.array([2.0, 2.0, 2.0])                                 \n",
    "x*y                                                                        # Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "honey-sleeve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763 ns ± 16.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x*y                                 # In Ipython console, we can use this to measure the time elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-budapest",
   "metadata": {},
   "source": [
    "Vectorization and Broadcasting may seem like the same thing and they are to a certain degree. Say if we are multiplying two arrays, NumPy delegates the loop to pre-compiled, optimized C code under the hood. This process is called vectorization of the multiplication operator. Vectorization avoids using of loop which results in the code running faster. <u>Broadcasting, defines how arithmetic operations are to be performed on arrays of unequal size.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wrapped-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = np.array([1,64,1,65,65])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-suite",
   "metadata": {},
   "source": [
    "Let's say we want to add 4 to all the elements of the array.\n",
    "\n",
    "If we do that, then the element 4 is stretched to [4,4,4,4,4] to match the size of the array we are adding to. In other words, the smaller array is broadcast over the larger one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "gorgeous-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 66,  3, 67, 67])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-surge",
   "metadata": {},
   "source": [
    "Now, Numpy doesn't actually create copies of the elements and create a new \"stretched\" array but raher the inherent computations are such that the the operation could be performed across all the elements of the array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-difficulty",
   "metadata": {},
   "source": [
    "<a href = \"https://blog.paperspace.com/numpy-optimization-vectorization-and-broadcasting/\"> Vectorization and Broadcasting </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-texas",
   "metadata": {},
   "source": [
    "<a href = \"https://www.youtube.com/watch?v=0u9OzBSRZec\">More on Broadcasting </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-voluntary",
   "metadata": {},
   "source": [
    "<a href = \"https://realpython.com/numpy-array-programming/\">Numpy Array Programming</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
